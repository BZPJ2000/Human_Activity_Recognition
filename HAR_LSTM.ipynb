{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:16:49.914256Z",
     "start_time": "2025-02-07T12:16:46.584038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from memory_profiler import profile\n",
    "import time"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:16:49.945327Z",
     "start_time": "2025-02-07T12:16:49.925765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.df = pd.read_excel(file_path)\n",
    "\n",
    "        self.df = self.df.groupby('Activity').apply(lambda x: x.sample(frac=0.1)).reset_index(drop=True)\n",
    "\n",
    "        # 分割特征和标签\n",
    "        self.features = self.df.drop(['subject', 'Activity', 'ActivityName'], axis=1).values\n",
    "        self.labels = self.df['Activity'].values\n",
    "\n",
    "        # 特征归一化\n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "\n",
    "        # 转换为张量\n",
    "        self.features = torch.FloatTensor(self.features)\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:10.351117Z",
     "start_time": "2025-02-07T12:16:50.227590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据\n",
    "train = r'E:\\A_workbench\\A-lab\\25-2-4\\Human-Activity-Recognition-master\\my_data\\train_dataset.xlsx'\n",
    "test = r'E:\\A_workbench\\A-lab\\25-2-4\\Human-Activity-Recognition-master\\my_data\\test_dataset.xlsx'\n",
    "train_dataset = ActivityDataset(train)\n",
    "test_dataset = ActivityDataset(test)\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:10.382148Z",
     "start_time": "2025-02-07T12:20:10.368140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # Batch Normalization\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 添加序列维度 (batch_size, 1, input_dim)\n",
    "        x = x.unsqueeze(1)  # 关键修改：将2D输入转换为3D\n",
    "\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # 前向传播\n",
    "        out, (h_n, c_n) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 取最后一个时间步的输出\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Batch Normalization和Dropout\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # 全连接层\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:10.428984Z",
     "start_time": "2025-02-07T12:20:10.399378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取输入维度和输出维度\n",
    "input_dim = train_dataset.features.shape[1]\n",
    "output_dim = len(torch.unique(train_dataset.labels))\n",
    "\n",
    "# Check the number of unique classes\n",
    "num_classes = len(torch.unique(train_dataset.labels))\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Remap labels to be zero-indexed if necessary\n",
    "unique_labels = torch.unique(train_dataset.labels)\n",
    "label_mapping = {label.item(): idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "train_dataset.labels = torch.tensor([label_mapping[label.item()] for label in train_dataset.labels])\n",
    "test_dataset.labels = torch.tensor([label_mapping[label.item()] for label in test_dataset.labels])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:10.475166Z",
     "start_time": "2025-02-07T12:20:10.446408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型\n",
    "model = LSTMModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    output_dim=output_dim,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(880, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:10.506362Z",
     "start_time": "2025-02-07T12:20:10.493748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# 训练设备选择（GPU 或 CPU）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 50\n",
    "best_val_acc = 0.0\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:30.183180Z",
     "start_time": "2025-02-07T12:20:10.538213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 记录训练时间\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算准确率\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        train_acc += (preds == labels).sum().item()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 计算平均损失和准确率\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            val_acc += (preds == labels).sum().item()\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    val_acc /= len(test_loader.dataset)\n",
    "\n",
    "    # 打印训练信息\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_activity_model.pth')\n",
    "\n",
    "# 记录训练结束时间\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Total Execution Time: {execution_time:.2f} seconds')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Train Loss: 0.8236, Train Acc: 0.7087\n",
      "Val Loss: 0.7836, Val Acc: 0.7886\n",
      "Epoch [2/50]\n",
      "Train Loss: 0.3673, Train Acc: 0.8720\n",
      "Val Loss: 0.7106, Val Acc: 0.7780\n",
      "Epoch [3/50]\n",
      "Train Loss: 0.2440, Train Acc: 0.9260\n",
      "Val Loss: 0.6830, Val Acc: 0.8153\n",
      "Epoch [4/50]\n",
      "Train Loss: 0.1657, Train Acc: 0.9527\n",
      "Val Loss: 0.9956, Val Acc: 0.7265\n",
      "Epoch [5/50]\n",
      "Train Loss: 0.1202, Train Acc: 0.9630\n",
      "Val Loss: 0.8021, Val Acc: 0.7815\n",
      "Epoch [6/50]\n",
      "Train Loss: 0.0911, Train Acc: 0.9721\n",
      "Val Loss: 0.9415, Val Acc: 0.7726\n",
      "Epoch [7/50]\n",
      "Train Loss: 0.0877, Train Acc: 0.9769\n",
      "Val Loss: 0.7540, Val Acc: 0.8224\n",
      "Epoch [8/50]\n",
      "Train Loss: 0.0587, Train Acc: 0.9842\n",
      "Val Loss: 1.0161, Val Acc: 0.7620\n",
      "Epoch [9/50]\n",
      "Train Loss: 0.0574, Train Acc: 0.9788\n",
      "Val Loss: 0.9849, Val Acc: 0.7726\n",
      "Epoch [10/50]\n",
      "Train Loss: 0.0532, Train Acc: 0.9806\n",
      "Val Loss: 1.0157, Val Acc: 0.7744\n",
      "Epoch [11/50]\n",
      "Train Loss: 0.0543, Train Acc: 0.9854\n",
      "Val Loss: 0.9716, Val Acc: 0.7922\n",
      "Epoch [12/50]\n",
      "Train Loss: 0.0287, Train Acc: 0.9921\n",
      "Val Loss: 1.0161, Val Acc: 0.7886\n",
      "Epoch [13/50]\n",
      "Train Loss: 0.0227, Train Acc: 0.9951\n",
      "Val Loss: 0.9814, Val Acc: 0.7904\n",
      "Epoch [14/50]\n",
      "Train Loss: 0.0199, Train Acc: 0.9970\n",
      "Val Loss: 0.8244, Val Acc: 0.8153\n",
      "Epoch [15/50]\n",
      "Train Loss: 0.0180, Train Acc: 0.9945\n",
      "Val Loss: 0.9657, Val Acc: 0.7940\n",
      "Epoch [16/50]\n",
      "Train Loss: 0.0106, Train Acc: 0.9988\n",
      "Val Loss: 0.9201, Val Acc: 0.8028\n",
      "Epoch [17/50]\n",
      "Train Loss: 0.0135, Train Acc: 0.9976\n",
      "Val Loss: 0.9324, Val Acc: 0.7975\n",
      "Epoch [18/50]\n",
      "Train Loss: 0.0141, Train Acc: 0.9976\n",
      "Val Loss: 0.9537, Val Acc: 0.7993\n",
      "Epoch [19/50]\n",
      "Train Loss: 0.0139, Train Acc: 0.9970\n",
      "Val Loss: 1.0060, Val Acc: 0.7851\n",
      "Epoch [20/50]\n",
      "Train Loss: 0.0133, Train Acc: 0.9970\n",
      "Val Loss: 0.9611, Val Acc: 0.8011\n",
      "Epoch [21/50]\n",
      "Train Loss: 0.0114, Train Acc: 0.9994\n",
      "Val Loss: 0.9743, Val Acc: 0.8011\n",
      "Epoch [22/50]\n",
      "Train Loss: 0.0092, Train Acc: 0.9988\n",
      "Val Loss: 0.9273, Val Acc: 0.8082\n",
      "Epoch [23/50]\n",
      "Train Loss: 0.0117, Train Acc: 0.9988\n",
      "Val Loss: 0.9556, Val Acc: 0.8046\n",
      "Epoch [24/50]\n",
      "Train Loss: 0.0136, Train Acc: 0.9988\n",
      "Val Loss: 0.9443, Val Acc: 0.8046\n",
      "Epoch [25/50]\n",
      "Train Loss: 0.0126, Train Acc: 0.9982\n",
      "Val Loss: 0.9249, Val Acc: 0.8117\n",
      "Epoch [26/50]\n",
      "Train Loss: 0.0116, Train Acc: 0.9988\n",
      "Val Loss: 0.9696, Val Acc: 0.8028\n",
      "Epoch [27/50]\n",
      "Train Loss: 0.0118, Train Acc: 0.9982\n",
      "Val Loss: 0.9828, Val Acc: 0.8011\n",
      "Epoch [28/50]\n",
      "Train Loss: 0.0132, Train Acc: 0.9970\n",
      "Val Loss: 1.0022, Val Acc: 0.7940\n",
      "Epoch [29/50]\n",
      "Train Loss: 0.0145, Train Acc: 0.9976\n",
      "Val Loss: 0.9647, Val Acc: 0.7975\n",
      "Epoch [30/50]\n",
      "Train Loss: 0.0114, Train Acc: 0.9976\n",
      "Val Loss: 0.8671, Val Acc: 0.8082\n",
      "Epoch [31/50]\n",
      "Train Loss: 0.0098, Train Acc: 1.0000\n",
      "Val Loss: 0.9183, Val Acc: 0.8117\n",
      "Epoch [32/50]\n",
      "Train Loss: 0.0097, Train Acc: 0.9994\n",
      "Val Loss: 0.9045, Val Acc: 0.8135\n",
      "Epoch [33/50]\n",
      "Train Loss: 0.0111, Train Acc: 0.9988\n",
      "Val Loss: 0.9253, Val Acc: 0.8099\n",
      "Epoch [34/50]\n",
      "Train Loss: 0.0115, Train Acc: 0.9982\n",
      "Val Loss: 0.9435, Val Acc: 0.8046\n",
      "Epoch [35/50]\n",
      "Train Loss: 0.0150, Train Acc: 0.9964\n",
      "Val Loss: 0.9091, Val Acc: 0.8117\n",
      "Epoch [36/50]\n",
      "Train Loss: 0.0094, Train Acc: 1.0000\n",
      "Val Loss: 0.9569, Val Acc: 0.7975\n",
      "Epoch [37/50]\n",
      "Train Loss: 0.0088, Train Acc: 0.9994\n",
      "Val Loss: 0.9320, Val Acc: 0.8064\n",
      "Epoch [38/50]\n",
      "Train Loss: 0.0084, Train Acc: 0.9988\n",
      "Val Loss: 1.0018, Val Acc: 0.7940\n",
      "Epoch [39/50]\n",
      "Train Loss: 0.0104, Train Acc: 0.9988\n",
      "Val Loss: 0.9344, Val Acc: 0.8064\n",
      "Epoch [40/50]\n",
      "Train Loss: 0.0099, Train Acc: 0.9988\n",
      "Val Loss: 0.9378, Val Acc: 0.8099\n",
      "Epoch [41/50]\n",
      "Train Loss: 0.0134, Train Acc: 0.9964\n",
      "Val Loss: 0.8576, Val Acc: 0.8153\n",
      "Epoch [42/50]\n",
      "Train Loss: 0.0086, Train Acc: 0.9994\n",
      "Val Loss: 1.0024, Val Acc: 0.7833\n",
      "Epoch [43/50]\n",
      "Train Loss: 0.0097, Train Acc: 0.9988\n",
      "Val Loss: 0.9717, Val Acc: 0.7993\n",
      "Epoch [44/50]\n",
      "Train Loss: 0.0088, Train Acc: 0.9994\n",
      "Val Loss: 0.9263, Val Acc: 0.8082\n",
      "Epoch [45/50]\n",
      "Train Loss: 0.0114, Train Acc: 0.9988\n",
      "Val Loss: 0.9461, Val Acc: 0.8028\n",
      "Epoch [46/50]\n",
      "Train Loss: 0.0128, Train Acc: 0.9982\n",
      "Val Loss: 0.9776, Val Acc: 0.7922\n",
      "Epoch [47/50]\n",
      "Train Loss: 0.0158, Train Acc: 0.9964\n",
      "Val Loss: 0.9765, Val Acc: 0.7922\n",
      "Epoch [48/50]\n",
      "Train Loss: 0.0089, Train Acc: 0.9988\n",
      "Val Loss: 0.9948, Val Acc: 0.7975\n",
      "Epoch [49/50]\n",
      "Train Loss: 0.0102, Train Acc: 0.9976\n",
      "Val Loss: 0.9339, Val Acc: 0.8082\n",
      "Epoch [50/50]\n",
      "Train Loss: 0.0104, Train Acc: 0.9982\n",
      "Val Loss: 1.0521, Val Acc: 0.7815\n",
      "Total Execution Time: 19.62 seconds\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:30.228725Z",
     "start_time": "2025-02-07T12:20:30.190073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_activity_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 预测测试集\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 生成混淆矩阵\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# 计算准确率\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[348  13  12  28   4]\n",
      " [ 11  43   3   2   1]\n",
      " [  2   1  10   3   6]\n",
      " [  3   0   2   5   9]\n",
      " [  0   0   0   0  57]]\n",
      "Test Accuracy: 0.8224\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:30.323831Z",
     "start_time": "2025-02-07T12:20:30.262750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 torch.autograd.profiler 记录模型运行时间\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    model(inputs)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "\n",
    "# 使用 memory_profiler 记录内存消耗\n",
    "@profile\n",
    "def memory_consumption():\n",
    "    model(inputs)\n",
    "\n",
    "\n",
    "memory_consumption()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 aten::unsqueeze         7.78%     146.000us         8.00%     150.000us     150.000us             1  \n",
      "                aten::as_strided         0.59%      11.000us         0.59%      11.000us       0.367us            30  \n",
      "                     aten::zeros         7.09%     133.000us         7.52%     141.000us      70.500us             2  \n",
      "                     aten::empty         0.43%       8.000us         0.43%       8.000us       1.000us             8  \n",
      "                     aten::zero_         0.11%       2.000us         0.11%       2.000us       1.000us             2  \n",
      "                        aten::to         0.05%       1.000us         0.05%       1.000us       0.500us             2  \n",
      "                      aten::lstm        16.63%     312.000us        66.95%       1.256ms       1.256ms             1  \n",
      "       aten::cudnn_is_acceptable         0.05%       1.000us         0.05%       1.000us       1.000us             1  \n",
      "                 aten::transpose         0.85%      16.000us         1.12%      21.000us       3.000us             7  \n",
      "                    aten::unbind         1.12%      21.000us         1.44%      27.000us       6.750us             4  \n",
      "                    aten::select         0.64%      12.000us         0.64%      12.000us       1.714us             7  \n",
      "                    aten::linear         7.89%     148.000us        28.89%     542.000us     108.400us             5  \n",
      "                         aten::t         1.55%      29.000us         2.08%      39.000us       7.800us             5  \n",
      "                      aten::view         0.80%      15.000us         0.80%      15.000us       1.875us             8  \n",
      "                     aten::addmm        15.67%     294.000us        18.18%     341.000us      68.200us             5  \n",
      "                    aten::expand         0.32%       6.000us         0.32%       6.000us       1.200us             5  \n",
      "                     aten::copy_         2.19%      41.000us         2.19%      41.000us       8.200us             5  \n",
      "              aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us            10  \n",
      "                      aten::add_         1.28%      24.000us         1.28%      24.000us       6.000us             4  \n",
      "              aten::unsafe_chunk         0.16%       3.000us         7.25%     136.000us      68.000us             2  \n",
      "              aten::unsafe_split         0.85%      16.000us         7.09%     133.000us      66.500us             2  \n",
      "                    aten::narrow         5.92%     111.000us         6.24%     117.000us      14.625us             8  \n",
      "                     aten::slice         0.59%      11.000us         0.69%      13.000us       1.300us            10  \n",
      "                  aten::sigmoid_         8.16%     153.000us         8.16%     153.000us      25.500us             6  \n",
      "                     aten::tanh_         0.75%      14.000us         0.75%      14.000us       7.000us             2  \n",
      "                       aten::mul         1.60%      30.000us         1.60%      30.000us       5.000us             6  \n",
      "                      aten::tanh         0.48%       9.000us         0.48%       9.000us       4.500us             2  \n",
      "                     aten::stack         1.01%      19.000us         1.97%      37.000us       9.250us             4  \n",
      "                       aten::cat         0.91%      17.000us         0.91%      17.000us       4.250us             4  \n",
      "                aten::batch_norm         6.56%     123.000us        14.61%     274.000us     274.000us             1  \n",
      "    aten::_batch_norm_impl_index         6.40%     120.000us         8.05%     151.000us     151.000us             1  \n",
      "         aten::native_batch_norm         1.49%      28.000us         1.60%      30.000us      30.000us             1  \n",
      "                aten::empty_like         0.05%       1.000us         0.11%       2.000us       2.000us             1  \n",
      "                   aten::dropout         0.05%       1.000us         0.05%       1.000us       1.000us             1  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.876ms\n",
      "\n",
      "ERROR: Could not find file C:\\Users\\yuyu\\AppData\\Local\\Temp\\ipykernel_8060\\3992666463.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\profiler.py:176: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:30.354850Z",
     "start_time": "2025-02-07T12:20:30.341336Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T12:20:30.401282Z",
     "start_time": "2025-02-07T12:20:30.387777Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
